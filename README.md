Hereâ€™s the properly formatted **`README.md`** file code you asked for:

```markdown
# ğŸ“Š TP5: RNN vs Feed-Forward - RÃ©sultats et Analyse

## ğŸ¯ Objectif
Comparer les performances des rÃ©seaux de neurones rÃ©currents (RNN) et des rÃ©seaux feed-forward (FF) pour la prÃ©diction de mots dans des phrases en franÃ§ais.

---

## ğŸ“ Structure du Projet
```text
TP5_RNN_IA_NLP/
â”œâ”€â”€ data.py              # Corpus de phrases
â”œâ”€â”€ preprocessing.py     # PrÃ©paration des donnÃ©es
â”œâ”€â”€ rnn_model.py         # Architecture RNN
â”œâ”€â”€ ff_models.py         # Architectures FF-2 et FF-6
â”œâ”€â”€ train_models.py      # Script d'entraÃ®nement
â”œâ”€â”€ test_models.py       # Script de test et analyse
â””â”€â”€ README.md            # Ce fichier
```

---

## ğŸš€ Comment exÃ©cuter

### Installation
```bash
pip install tensorflow numpy
```

### EntraÃ®nement
```bash
python train_models.py
```
â¡ï¸ EntraÃ®ne 3 modÃ¨les (RNN, FF-2, FF-6) pendant 200 epochs chacun.

### Test
```bash
python test_models.py
```
â¡ï¸ GÃ©nÃ¨re l'analyse complÃ¨te et les rÃ©sultats.

---

## ğŸ“Š RÃ©sultats Obtenus

### âœ… Question 6: Test du RNN
**SÃ©quence test :** `le chien que le chat _____`  
**Mot prÃ©dit par le RNN :** `effraie`  
**Analyse :** Correct ! Correspond Ã  la phrase du corpus :  
`le chat que le chien effraie se cache`

---

### âœ… Question 7: Comparaison des 3 modÃ¨les
**Phrase test :** `le chat que le chien a vu _____`  
**Mot attendu :** `mange`

- **FF-2 (2 derniers mots) :** `a vu â†’ mange`  
- **FF-6 (6 derniers mots) :** `chat que le chien a vu â†’ mange`  
- **RNN (sÃ©quence complÃ¨te) :** `le chat que le chien a vu â†’ mange`

ğŸ“Œ **RÃ©sultat :** Les 3 modÃ¨les prÃ©disent correctement `mange` !

---

## ğŸ” DÃ©monstration ClÃ©: Avantage du RNN
Test avec contexte progressif :

| Contexte                  | PrÃ©diction | Statut   |
|---------------------------|------------|----------|
| "a vu"                    | "le"       | âŒ       |
| "chien a vu"              | "chien"    | âŒ       |
| "le chien a vu"           | "chien"    | âŒ       |
| "que le chien a vu"       | "voisin"   | âŒ       |
| "chat que le chien a vu"  | "mange"    | âœ…       |
| "sÃ©quence complÃ¨te"       | "mange"    | âœ…       |

---

## ğŸ“ˆ Analyse des RÃ©sultats

### Pourquoi FF-2 prÃ©dit correctement ?
- **Pattern local :** La sÃ©quence "a vu" est presque toujours suivie de "mange" dans ce corpus spÃ©cifique.  
- **Limitation :** BasÃ© uniquement sur les 2 derniers mots, pas sur la structure globale de la phrase.

### Pourquoi le RNN est supÃ©rieur ?
- **MÃ©moire contextuelle :** Retient le sujet "le chat" mÃªme aprÃ¨s 5 mots intermÃ©diaires.  
- **DÃ©pendances longues :** Relie un sujet distant (le chat) Ã  son verbe (mange).  
- **AdaptabilitÃ© :** Fonctionne avec des contextes de longueur variable.  

---

## ğŸ¯ Conclusion

| ModÃ¨le | Avantages            | Limitations                        |
|--------|----------------------|------------------------------------|
| FF-2   | Simple, rapide       | Contexte limitÃ© (2 mots)           |
| FF-6   | Contexte plus large  | FenÃªtre fixe, pas de mÃ©moire       |
| RNN    | MÃ©moire temporelle   | Plus complexe Ã  entraÃ®ner          |

â¡ï¸ **Le RNN est le plus cohÃ©rent car il :**
- Exploite toute la sÃ©quence.  
- Maintient une mÃ©moire du sujet.  
- Capture les relations sujet-verbe Ã©loignÃ©es.  
- Sâ€™adapte aux sÃ©quences de longueur variable.  

---

## ğŸ“‹ SpÃ©cifications Techniques
- **ModÃ¨les :** RNN (SimpleRNN 16 unitÃ©s), FF-2, FF-6  
- **DonnÃ©es :** 6 phrases, vocabulaire de 18 mots  
- **Performance :** 100% dâ€™accuracy sur le corpus dâ€™entraÃ®nement  
```

Would you like me to also add **visual plots of training accuracy/loss curves** (in Markdown with placeholders for graphs), so the README looks more like a research report?
