# ğŸ“Š TP5: RNN vs Feed-Forward - RÃ©sultats et Analyse

## ğŸ¯ Objectif
Comparer les performances des rÃ©seaux de neurones rÃ©currents (RNN) et des rÃ©seaux feed-forward (FF) pour la prÃ©diction de mots dans des phrases en franÃ§ais.



## ğŸ“ Structure du Projet
```text
TP5_RNN_IA_NLP/
â”œâ”€â”€ data.py              # Corpus de phrases
â”œâ”€â”€ preprocessing.py     # PrÃ©paration des donnÃ©es
â”œâ”€â”€ rnn_model.py         # Architecture RNN
â”œâ”€â”€ ff_models.py         # Architectures FF-2 et FF-6
â”œâ”€â”€ train_models.py      # Script d'entraÃ®nement
â”œâ”€â”€ test_models.py       # Script de test et analyse
â””â”€â”€ README.md            # Ce fichier
ğŸš€ Comment exÃ©cuterInstallationBashpip install tensorflow numpy
EntraÃ®nementBashpython train_models.py
EntraÃ®ne 3 modÃ¨les (RNN, FF-2, FF-6) pendant 200 epochs chacun.TestBashpython test_models.py
GÃ©nÃ¨re l'analyse complÃ¨te et les rÃ©sultats.ğŸ“Š RÃ©sultats Obtenusâœ… Question 6: Test du RNNPlaintextSÃ©quence test: le chien que le chat _____
Mot prÃ©dit par le RNN: 'effraie'
Analyse: Correct! Correspond Ã  la phrase du corpus: "le chat que le chien effraie se cache"
âœ… Question 7: Comparaison des 3 modÃ¨lesTest principal:Phrase: le chat que le chien a vu _____Mot attendu: 'mange'FF-2 (2 derniers mots): a vu â†’ 'mange'FF-6 (6 derniers mots): chat que le chien a vu â†’ 'mange'RNN (sÃ©quence complÃ¨te): le chat que le chien a vu â†’ 'mange'ğŸ“Œ RÃ©sultat: Les 3 modÃ¨les prÃ©dissent correctement 'mange' !ğŸ” DÃ©montration ClÃ©: Avantage du RNNTest avec contexte progressif :ContextePrÃ©dictionStatut"a vu"'le'âŒ Incorrect"chien a vu"'chien'âŒ Incorrect"le chien a vu"'chien'âŒ Incorrect"que le chien a vu"'voisin'âŒ Incorrect"chat que le chien a vu"'mange'âœ… Correct"sÃ©quence complÃ¨te"'mange'âœ… CorrectğŸ“ˆ Analyse des RÃ©sultatsPourquoi FF-2 prÃ©dit correctement ?Pattern local: La sÃ©quence "a vu" est presque toujours suivie de "mange" dans ce corpus spÃ©cifique.Limitation: BasÃ© uniquement sur les 2 derniers mots, pas sur la structure globale de la phrase.Pourquoi le RNN est supÃ©rieur ?MÃ©moire contextuelle: Retient le sujet "le chat" mÃªme aprÃ¨s 5 mots intermÃ©diaires.DÃ©pendances longues: Relie un sujet distant (le chat) Ã  son verbe (mange).AdaptabilitÃ©: Fonctionne avec des contextes de longueur variable.ğŸ¯ ConclusionModÃ¨leAvantagesLimitationsFF-2Simple, rapideContexte limitÃ© (2 mots)FF-6Contexte plus largeFenÃªtre fixe, pas de mÃ©moireRNNMÃ©moire temporellePlus complexe Ã  entraÃ®nerLe RNN est le plus cohÃ©rent car il :Exploite toute la sÃ©quence.Maintient une mÃ©moire du sujet.Capture les relations sujet-verbe Ã©loignÃ©es.S'adapte aux sÃ©quences de longueur variable.ğŸ“‹ SpÃ©cifications TechniquesModÃ¨les : RNN (SimpleRNN 16 unitÃ©s), FF-2, FF-6.DonnÃ©es : 6 phrases, vocabulaire de 18 mots.Performance : 100% d'accuracy sur le corpus d'entraÃ®nement.
